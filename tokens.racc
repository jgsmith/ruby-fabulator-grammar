class Fabulator::Grammar::TokenParser

  start rules

rule
  rules: anchored_rule { result = Fabulator::Grammar::Expr::Token.new; result.add_alternative(val[0]) }
       | rules PIPE anchored_rule { result = val[0]; result.add_alternative(val[2]) }

  anchored_rule: rule { result = val[0] }
       | left_anchor rule { result = val[1]; result.anchor_start(val[0]) }
       | rule right_anchor { result = val[0]; result.anchor_end(val[1]) }
       | left_anchor rule right_anchor { result = val[1]; result.anchor_start(val[0]); result.anchor_end(val[2]) }

  left_anchor: CARET { result = '^' }
       | CARET CARET { result = '^^' }

  right_anchor: DOLLAR { result = '$' }
       | DOLLAR DOLLAR { result = '$$' }

  rule: { result = Fabulator::Grammar::Expr::TokenAlternative.new; }
      | rule sequence { result = val[0]; result.add_sequence(val[1]); }

  sequence: atom sequence_qualifiers { result = Fabulator::Grammar::Expr::Sequence.new(nil, val[0], val[1]) }
          | atom { result = Fabulator::Grammar::Expr::Sequence.new(nil, val[0]) }

  atom: text { result = Fabulator::Grammar::Expr::Text.new(val[0]) }
      | DOT { result = Fabulator::Grammar::Expr::Any.new }
      | LP rules RP { result = val[1] }
      | LB atom_expr RB { result = val[1] }

  atom_expr: char_set_expr

 #{ result = Fabulator::Grammar::Expr::CharSet.new; result.universal }
  char_set_expr: char_set { result = val[0] }
      | MINUS char_set { result = Fabulator::Grammar::Expr::CharSet.new; result.universal; result.but_not(val[1]) }
      | char_set_expr PLUS char_set { result = val[0].or(val[2]) }
      | char_set_expr MINUS char_set { result = val[0].but_not(val[2]) }

  char_set: LB char_set_text RB { result = Fabulator::Grammar::Expr::CharSet.new(val[1]) }
      | COLON NCNAME COLON { result = Fabulator::Grammar::Expr::CharClass.new(val[1]) }
      | LP char_set_expr RP { result = val[1] }

  char_set_text: { result = '' }
      | char_set_text CHAR_TEXT { result = val[0] + val[1] }
      | char_set_text MINUS CHAR_TEXT { result = val[0] + '-' + val[2] }
      | char_set_text PLUS CHAR_TEXT { result = val[0] + '+' + val[2] }
      
  text: qname { result = val[0] }
      | TEXT { result = val[0] }
      | INTEGER { result = val[0] }
      | COMMA { result = val[0] }

  qname: NCNAME { result = val[0] }
       | NCNAME COLON NCNAME { result = val[0] + ':' + val[2] }

  sequence_qualifiers: STAR { result = [ :zero_or_more ] }
      | STAR QUESTION { result = [ :zero_or_more, :min ] }
      | PLUS { result = [ :one_or_more ] }
      | PLUS QUESTION { result = [ :one_or_more, :min ] }
      | QUESTION { result = [ :zero_or_one ] }
      | QUESTION QUESTION { result = [ :zero_or_one, :min ] }
      | LLB INTEGER RB { result = [ :exact, val[1].to_i ] }
      | LLB INTEGER COMMA INTEGER RB { result = [ :range, val[1].to_i, val[3].to_i ] }
      | LLB INTEGER COMMA RB { result = [ :range, val[1], '' ] }
      | LLB INTEGER COMMA RB QUESTION { result = [ :min, :range, val[1], '' ] }
      | LLB INTEGER COMMA INTEGER RB QUESTION { result = [ :min, :range, val[1].to_i, val[3].to_i ] }
      

---- inner
  require 'fabulator/grammar'

  def parse(t)
    @source = t
    @curpos = 0 
    @col = 0
    @line = 0   

    @yydebug = true
      
    @last_token = nil

    @brackets = 0
  
    do_parse
  end
    
  def on_error(*args)
    raise Fabulator::Grammar::ParserError.new("unable to parse '#{args[1]}' near line #{@line + 1}, column #{@col}")
  end

  @@ops = {
    #'[{' => :LB_LC,
    #'}]' => :RC_RB,
    #'[[' => :LB_LB,
    #']]' => :RB_RB,
    '['  => :LB,
    ']'  => :RB,
    '('  => :LP,
    ')'  => :RP,
    #'{'  => :LC,
    #'}'  => :RC,
    #'#'  => :HASH,
    '$'  => :DOLLAR,
    '^'  => :CARET,
    #'&'  => :AND,
    '*'  => :STAR,
    '+'  => :PLUS,
    '-'  => :MINUS,
    '?'  => :QUESTION,
    '.'  => :DOT,
    '|'  => :PIPE,
    ','  => :COMMA,
    ':'  => :COLON
  }


  @@regex = {
     :simple_tokens => %r{^(#{Regexp.union(@@ops.keys.sort_by{|a| a.length}.reverse.collect{ |k| k })})},
    :ncname => %r{(?:[a-zA-Z_][-a-zA-Z0-9_.]*)}
  }

 #puts @@regex[:simple_tokens]

  @@regex[:qname] = %r{((?:#{@@regex[:ncname]}:)?#{@@regex[:ncname]})}
  @@regex[:general] = Regexp.compile(%{^#{@@regex[:qname]}|#{@@regex[:simple_tokens]}})

  def next_token
    @token = nil
    white_space = 0
    new_line = 0
    while @curpos < @source.length && @source[@curpos..@curpos] =~ /\s/ do
      if @source[@curpos..@curpos] =~ /\n/
        new_line = new_line + 1
        @line = @line + 1
        @col = 0
      else
        @col = @col + 1
      end
      @curpos = @curpos + 1
      white_space = white_space + 1   
    end

    # skip comments delimited by (:  :)
    # comments can be nested
    # these are XPath 2.0 comments
    #
    if @curpos < @source.length && @source[@curpos..@curpos+1] == '(:'
      comment_depth = 1
      @curpos = @curpos + 2
      @col = @col + 2
      while comment_depth > 0 && @curpos < @source.length
        if @source[@curpos..@curpos+1] == '(:'
          comment_depth = comment_depth + 1
          @curpos = @curpos + 1
          @col = @col + 1
        end
        if @source[@curpos..@curpos+1] == ':)'
          comment_depth = comment_depth - 1
          @curpos = @curpos + 1
          @col = @col + 1
        end
        @curpos = @curpos + 1
        @col = @col + 1
      end
      white_space = white_space + 1
    end

    while @curpos < @source.length && @source[@curpos..@curpos] =~ /\s/ do
      if @source[@curpos..@curpos] =~ /\n/
        new_line = new_line + 1
        @line = @line + 1
        @col = 0
      else
        @col = @col + 1
      end
      @curpos = @curpos + 1
      white_space = white_space + 1
    end

    if @curpos >= @source.length
      @last_token = nil
      return [ false, false ]
    end

#    case @source[@curpos..@curpos]
#      when '<': @token = [ :LT, '<' ]
#      when '>': @token = [ :GT, '>' ]
#      when '[': @token = [ :LB, '[' ]
#      when ']': @token = [ :RB, ']' ]
#      when '(': @token = [ :LP, '(' ]
#      when ')': @token = [ :RP, ')' ]
#      when '{': @token = [ :LC, '{' ]
#      when '}': @token = [ :RC, '}' ]
#      when ':': @token = [ :COLON, ':' ]
#      when ',': @token = [ :COMMA, ',' ]
#      when '|': @token = [ :PIPE, '|' ]
#      when '*': @token = [ :STAR, '*' ]
#      when '+': @token = [ :PLUS, '+' ]
#      when '.': @token = [ :DOT,  '.' ]
#      when '?': @token = [ :QUESTION, '?' ]
#      when '$': @token = [ :DOLLAR, '$' ]
#      when '^': @token = [ :CARET, '^' ]
#    end

    res = @@regex[:simple_tokens].match(@source[@curpos..@source.length-1])
    if !res.nil?
      if !res[1].nil?
        @token = [ @@ops[res[1]], res[1] ]
      end
    end

    if @token.nil?
      # get longest sequence of non-special characters
      # if it's all digits, report INTEGER
      # if it's a qname, report QNAME
      # otherwise, report TEXT
      @source[@curpos..@source.length-1] =~ /^(((\\.)|[^ \$\^\[\]\{\}\(\):,|*+.?])+)*/
      text = $1
      bits = text.split(/\\/)
      text = bits.join('')
      @curpos += bits.size - 1
      @col += bits.size - 1
      if text.length > 0
        if @source[@curpos+text.length .. @curpos+text.length] =~ /[*?+\{]/
# TODO: make sure we backtrack properly if the last character is escaped
          text = text[0..text.length-2]
          @token = [ :TEXT, text ]
        else
          case text
            when /^\d+$/: @token = [ :INTEGER, text ]
            when /^#{@@regex[:ncname]}$/: @token = [ :NCNAME, text ]
            else @token = [ :TEXT, text ]
          end
        end
      end
    end

    if @token.nil?
      puts "Uh oh... we don't know what to do: #{@source[@curpos .. @source.length-1]}"
    else
      @curpos += @token[1].length
      @col += @token[1].length
    end

    if @token[0] == :LB
      if @brackets == 0 && @source[@curpos..@source.length-1] =~ /^\s*\d/
        @token[0] = :LLB
      end
      @brackets += 1
    elsif @token[0] == :RB
      @brackets -= 1
    elsif @brackets > 1
      @token[0] = :CHAR_TEXT
    end

    return @token
  end
